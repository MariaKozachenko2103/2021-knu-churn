{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atlantic-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as mpl\n",
    "import math \n",
    "import seaborn as sea\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from numpy import percentile\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "particular-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset = pd.get_dummies(dataset)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"BankChurnML.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "del df[\"CLIENTNUM\"]\n",
    "del df[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"]\n",
    "del df[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wired-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test sets\n",
    "X = df.drop([\"Attrition_Flag\"], axis=1)\n",
    "Y = np.array(df['Attrition_Flag']) \n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X , Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "royal-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 89.964664 percent accurate\n",
      "[[ 249  214]\n",
      " [  70 2297]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.54      0.64       463\n",
      "         1.0       0.91      0.97      0.94      2367\n",
      "\n",
      "    accuracy                           0.90      2830\n",
      "   macro avg       0.85      0.75      0.79      2830\n",
      "weighted avg       0.89      0.90      0.89      2830\n",
      "\n",
      "KNN is 88.763251 percent accurate\n",
      "[[ 227  236]\n",
      " [  82 2285]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.49      0.59       463\n",
      "         1.0       0.91      0.97      0.93      2367\n",
      "\n",
      "    accuracy                           0.89      2830\n",
      "   macro avg       0.82      0.73      0.76      2830\n",
      "weighted avg       0.88      0.89      0.88      2830\n",
      "\n",
      "Naive Bayes is 88.339223 percent accurate\n",
      "[[ 287  176]\n",
      " [ 154 2213]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.62      0.63       463\n",
      "         1.0       0.93      0.93      0.93      2367\n",
      "\n",
      "    accuracy                           0.88      2830\n",
      "   macro avg       0.79      0.78      0.78      2830\n",
      "weighted avg       0.88      0.88      0.88      2830\n",
      "\n",
      "Linear SVMs is 90.176678 percent accurate\n",
      "[[ 262  201]\n",
      " [  77 2290]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.57      0.65       463\n",
      "         1.0       0.92      0.97      0.94      2367\n",
      "\n",
      "    accuracy                           0.90      2830\n",
      "   macro avg       0.85      0.77      0.80      2830\n",
      "weighted avg       0.90      0.90      0.90      2830\n",
      "\n",
      "Non Linear SVMs is 92.120141 percent accurate\n",
      "[[ 297  166]\n",
      " [  57 2310]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.64      0.73       463\n",
      "         1.0       0.93      0.98      0.95      2367\n",
      "\n",
      "    accuracy                           0.92      2830\n",
      "   macro avg       0.89      0.81      0.84      2830\n",
      "weighted avg       0.92      0.92      0.92      2830\n",
      "\n",
      "Decision Trees is 93.180212 percent accurate\n",
      "[[ 374   89]\n",
      " [ 104 2263]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.81      0.79       463\n",
      "         1.0       0.96      0.96      0.96      2367\n",
      "\n",
      "    accuracy                           0.93      2830\n",
      "   macro avg       0.87      0.88      0.88      2830\n",
      "weighted avg       0.93      0.93      0.93      2830\n",
      "\n",
      "Random Forests is 96.254417 percent accurate\n",
      "[[ 388   75]\n",
      " [  31 2336]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.84      0.88       463\n",
      "         1.0       0.97      0.99      0.98      2367\n",
      "\n",
      "    accuracy                           0.96      2830\n",
      "   macro avg       0.95      0.91      0.93      2830\n",
      "weighted avg       0.96      0.96      0.96      2830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Methods of Model Evaluation\n",
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "#\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "#\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "#\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, LR_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, LR_pred))\n",
    "#print ('Accuracy Score :',accuracy_score(Y_test, LR_pred))\n",
    "#\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, KNN_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, KNN_pred))\n",
    "#\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, NB_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, NB_pred))\n",
    "#\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, LSVM_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, LSVM_pred))\n",
    "#\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, NLSVM_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, NLSVM_pred))\n",
    "#\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, DT_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, DT_pred))\n",
    "#\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, RF_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mature-philip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests before tuning : 96.25441696113074 percent accurate\n",
      "Random Forests after tuning : 96.89045936395759 percent accurate\n"
     ]
    }
   ],
   "source": [
    "#Tuning Parametrs\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "params = {'n_estimators': [*range(100, 1100, 100)], 'max_features': [*range(1, 20)]}\n",
    "\n",
    "rscv = RandomizedSearchCV(estimator=random_forest, param_distributions=params, random_state=0)\n",
    "rscv.fit(X_train, Y_train)\n",
    "values = rscv.best_params_\n",
    "random_forest_best = RandomForestClassifier(n_estimators = values['n_estimators'], max_features = values['max_features'])\n",
    "random_forest_best.fit(X_train, Y_train)\n",
    "Y_pred = random_forest_best.predict(X_test)\n",
    "print(\"Random Forests before tuning : {0} percent accurate\".format(accuracy_score(RF_pred, Y_test)*100))\n",
    "print(\"Random Forests after tuning : {0} percent accurate\".format(accuracy_score(Y_test, Y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "juvenile-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average K-Fold Score : 0.967557251908397\n"
     ]
    }
   ],
   "source": [
    "#cross-validation\n",
    "kfold = KFold(9, shuffle=True, random_state=1)\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "scores = []\n",
    "\n",
    "for i in range(9):\n",
    "    result = next(kfold.split(df), None)\n",
    "    \n",
    "    X_train = df.iloc[result[0], 1:19]\n",
    "    X_test = df.iloc[result[1], 1:19]\n",
    "    \n",
    "    y_train = df.iloc[result[0], 0]\n",
    "    y_test = df.iloc[result[1], 0]\n",
    "    \n",
    "    classifier = classifier.fit(X_train,y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, predicted))\n",
    "    \n",
    "    \n",
    "\n",
    "print('Average K-Fold Score :' , np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aware-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BankChurnMLfunc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-heating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-finland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
