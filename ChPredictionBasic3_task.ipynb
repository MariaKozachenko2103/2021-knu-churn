{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as mpl\n",
    "import math \n",
    "import seaborn as sea\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from numpy import percentile\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.077747</td>\n",
       "      <td>0.495431</td>\n",
       "      <td>0.079970</td>\n",
       "      <td>0.972136</td>\n",
       "      <td>0.040813</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.604136</td>\n",
       "      <td>0.311311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160522</td>\n",
       "      <td>0.582837</td>\n",
       "      <td>0.152928</td>\n",
       "      <td>0.550310</td>\n",
       "      <td>0.048793</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.481536</td>\n",
       "      <td>0.217217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.270163</td>\n",
       "      <td>0.050792</td>\n",
       "      <td>0.828173</td>\n",
       "      <td>0.074848</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.430576</td>\n",
       "      <td>0.279279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.393972</td>\n",
       "      <td>0.459674</td>\n",
       "      <td>0.385652</td>\n",
       "      <td>0.654799</td>\n",
       "      <td>0.049216</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.080080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590751</td>\n",
       "      <td>0.715137</td>\n",
       "      <td>0.555617</td>\n",
       "      <td>0.608359</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.665436</td>\n",
       "      <td>0.086086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition_Flag  Customer_Age  Gender  Dependent_count  Education_Level  \\\n",
       "0             1.0      0.409091     1.0              0.4              0.2   \n",
       "1             1.0      0.363636     1.0              1.0              0.0   \n",
       "2             1.0      0.704545     0.0              0.4              0.2   \n",
       "3             1.0      0.431818     0.0              0.4              0.2   \n",
       "4             1.0      0.477273     1.0              0.2              1.0   \n",
       "\n",
       "   Marital_Status  Income_Category  Card_Category  Months_on_book  \\\n",
       "0             0.5             0.25            0.0        0.534884   \n",
       "1             0.0             1.00            0.0        0.418605   \n",
       "2             0.5             0.00            0.0        0.813953   \n",
       "3             0.5             1.00            0.0        0.558140   \n",
       "4             1.0             0.50            0.0        0.674419   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                       0.4                0.166667               0.333333   \n",
       "1                       0.8                0.500000               0.333333   \n",
       "2                       0.8                0.333333               0.333333   \n",
       "3                       1.0                0.166667               0.333333   \n",
       "4                       0.8                0.333333               0.000000   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0      0.077747             0.495431         0.079970              0.972136   \n",
       "1      0.160522             0.582837         0.152928              0.550310   \n",
       "2      0.030162             0.270163         0.050792              0.828173   \n",
       "3      0.393972             0.459674         0.385652              0.654799   \n",
       "4      0.590751             0.715137         0.555617              0.608359   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0         0.040813        0.118644             0.604136               0.311311  \n",
       "1         0.048793        0.271186             0.481536               0.217217  \n",
       "2         0.074848        0.161017             0.430576               0.279279  \n",
       "3         0.049216        0.093220             0.650665               0.080080  \n",
       "4         0.047168        0.144068             0.665436               0.086086  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"BankChurnersFNum.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "del df[\"Unnamed: 0\"]\n",
    "del df[\"CLIENTNUM\"]\n",
    "del df[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"]\n",
    "del df[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\"]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Attrition_Flag\"], axis=1)\n",
    "Y = df[\"Attrition_Flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = np.array(X[0:int(0.80*len(X))])\\nY_train = np.array(Y[0:int(0.80*len(Y))])\\nX_test = np.array(X[int(0.80*len(X)):])\\nY_test = np.array(Y[int(0.80*len(Y)):])'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\"\"\"X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 90.669478 percent accurate\n",
      "[[ 188  129]\n",
      " [  48 1532]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.59      0.68       317\n",
      "         1.0       0.92      0.97      0.95      1580\n",
      "\n",
      "    accuracy                           0.91      1897\n",
      "   macro avg       0.86      0.78      0.81      1897\n",
      "weighted avg       0.90      0.91      0.90      1897\n",
      "\n",
      "KNN is 89.298893 percent accurate\n",
      "[[ 160  157]\n",
      " [  46 1534]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.50      0.61       317\n",
      "         1.0       0.91      0.97      0.94      1580\n",
      "\n",
      "    accuracy                           0.89      1897\n",
      "   macro avg       0.84      0.74      0.77      1897\n",
      "weighted avg       0.89      0.89      0.88      1897\n",
      "\n",
      "Naive Bayes is 88.771745 percent accurate\n",
      "[[ 209  108]\n",
      " [ 105 1475]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.66      0.66       317\n",
      "         1.0       0.93      0.93      0.93      1580\n",
      "\n",
      "    accuracy                           0.89      1897\n",
      "   macro avg       0.80      0.80      0.80      1897\n",
      "weighted avg       0.89      0.89      0.89      1897\n",
      "\n",
      "Linear SVMs is 91.091197 percent accurate\n",
      "[[ 198  119]\n",
      " [  50 1530]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.62      0.70       317\n",
      "         1.0       0.93      0.97      0.95      1580\n",
      "\n",
      "    accuracy                           0.91      1897\n",
      "   macro avg       0.86      0.80      0.82      1897\n",
      "weighted avg       0.91      0.91      0.91      1897\n",
      "\n",
      "Non Linear SVMs is 92.830785 percent accurate\n",
      "[[ 212  105]\n",
      " [  31 1549]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.67      0.76       317\n",
      "         1.0       0.94      0.98      0.96      1580\n",
      "\n",
      "    accuracy                           0.93      1897\n",
      "   macro avg       0.90      0.82      0.86      1897\n",
      "weighted avg       0.93      0.93      0.92      1897\n",
      "\n",
      "Decision Trees is 93.410648 percent accurate\n",
      "[[ 259   58]\n",
      " [  67 1513]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.82      0.81       317\n",
      "         1.0       0.96      0.96      0.96      1580\n",
      "\n",
      "    accuracy                           0.93      1897\n",
      "   macro avg       0.88      0.89      0.88      1897\n",
      "weighted avg       0.93      0.93      0.93      1897\n",
      "\n",
      "Random Forests is 96.468108 percent accurate\n",
      "[[ 274   43]\n",
      " [  24 1556]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89       317\n",
      "         1.0       0.97      0.98      0.98      1580\n",
      "\n",
      "    accuracy                           0.96      1897\n",
      "   macro avg       0.95      0.92      0.93      1897\n",
      "weighted avg       0.96      0.96      0.96      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "#\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "#\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "#\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, LR_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, LR_pred))\n",
    "#print ('Accuracy Score :',accuracy_score(Y_test, LR_pred))\n",
    "#\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, KNN_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, KNN_pred))\n",
    "#\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, NB_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, NB_pred))\n",
    "#\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, LSVM_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, LSVM_pred))\n",
    "#\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, NLSVM_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, NLSVM_pred))\n",
    "#\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, DT_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, DT_pred))\n",
    "#\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, RF_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[151  29]\n",
      " [ 14 860]]\n",
      "Accuracy Score : 0.959203036053131\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[151  29]\n",
      " [ 17 857]]\n",
      "Accuracy Score : 0.9563567362428842\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.84      0.87       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.93      0.91      0.92      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[149  31]\n",
      " [ 15 859]]\n",
      "Accuracy Score : 0.9563567362428842\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.92      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[151  29]\n",
      " [ 13 861]]\n",
      "Accuracy Score : 0.9601518026565465\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88       180\n",
      "         1.0       0.97      0.99      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[152  28]\n",
      " [ 15 859]]\n",
      "Accuracy Score : 0.959203036053131\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.88       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[153  27]\n",
      " [ 17 857]]\n",
      "Accuracy Score : 0.9582542694497154\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.87       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.93      0.92      0.92      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[150  30]\n",
      " [ 15 859]]\n",
      "Accuracy Score : 0.9573055028462998\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.92      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[147  33]\n",
      " [ 16 858]]\n",
      "Accuracy Score : 0.9535104364326376\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86       180\n",
      "         1.0       0.96      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.95      1054\n",
      "   macro avg       0.93      0.90      0.91      1054\n",
      "weighted avg       0.95      0.95      0.95      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[150  30]\n",
      " [ 18 856]]\n",
      "Accuracy Score : 0.9544592030360531\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.83      0.86       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.95      1054\n",
      "   macro avg       0.93      0.91      0.92      1054\n",
      "weighted avg       0.95      0.95      0.95      1054\n",
      "\n",
      "Average K-Fold Score : 0.9572000843348092\n"
     ]
    }
   ],
   "source": [
    "#implement cross-validation\n",
    "kfold = KFold(9, shuffle=True, random_state=1)\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "scores = []\n",
    "\n",
    "for i in range(9):\n",
    "    result = next(kfold.split(df), None)\n",
    "    \n",
    "    X_train = df.iloc[result[0], 1:19]\n",
    "    X_test = df.iloc[result[1], 1:19]\n",
    "    \n",
    "    y_train = df.iloc[result[0], 0]\n",
    "    y_test = df.iloc[result[1], 0]\n",
    "    \n",
    "    classifier = classifier.fit(X_train,y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, predicted))\n",
    "    \n",
    "    print ('Confusion Matrix :') \n",
    "    print(confusion_matrix(y_test, predicted)) \n",
    "    print ('Accuracy Score :',accuracy_score(y_test, predicted)) \n",
    "    print ('Report : ') \n",
    "    print (classification_report(y_test, predicted)) \n",
    "    \n",
    "\n",
    "print('Average K-Fold Score :' , np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
