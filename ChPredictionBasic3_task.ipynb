{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as mpl\n",
    "import math \n",
    "import seaborn as sea\n",
    "import statistics\n",
    "from scipy import stats\n",
    "from numpy import percentile\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.077747</td>\n",
       "      <td>0.495431</td>\n",
       "      <td>0.079970</td>\n",
       "      <td>0.972136</td>\n",
       "      <td>0.040813</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.604136</td>\n",
       "      <td>0.311311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160522</td>\n",
       "      <td>0.582837</td>\n",
       "      <td>0.152928</td>\n",
       "      <td>0.550310</td>\n",
       "      <td>0.048793</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.481536</td>\n",
       "      <td>0.217217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.270163</td>\n",
       "      <td>0.050792</td>\n",
       "      <td>0.828173</td>\n",
       "      <td>0.074848</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.430576</td>\n",
       "      <td>0.279279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.393972</td>\n",
       "      <td>0.459674</td>\n",
       "      <td>0.385652</td>\n",
       "      <td>0.654799</td>\n",
       "      <td>0.049216</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.080080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590751</td>\n",
       "      <td>0.715137</td>\n",
       "      <td>0.555617</td>\n",
       "      <td>0.608359</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.665436</td>\n",
       "      <td>0.086086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition_Flag  Customer_Age  Gender  Dependent_count  Education_Level  \\\n",
       "0             1.0      0.409091     1.0              0.4              0.2   \n",
       "1             1.0      0.363636     1.0              1.0              0.0   \n",
       "2             1.0      0.704545     0.0              0.4              0.2   \n",
       "3             1.0      0.431818     0.0              0.4              0.2   \n",
       "4             1.0      0.477273     1.0              0.2              1.0   \n",
       "\n",
       "   Marital_Status  Income_Category  Card_Category  Months_on_book  \\\n",
       "0             0.5             0.25            0.0        0.534884   \n",
       "1             0.0             1.00            0.0        0.418605   \n",
       "2             0.5             0.00            0.0        0.813953   \n",
       "3             0.5             1.00            0.0        0.558140   \n",
       "4             1.0             0.50            0.0        0.674419   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                       0.4                0.166667               0.333333   \n",
       "1                       0.8                0.500000               0.333333   \n",
       "2                       0.8                0.333333               0.333333   \n",
       "3                       1.0                0.166667               0.333333   \n",
       "4                       0.8                0.333333               0.000000   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0      0.077747             0.495431         0.079970              0.972136   \n",
       "1      0.160522             0.582837         0.152928              0.550310   \n",
       "2      0.030162             0.270163         0.050792              0.828173   \n",
       "3      0.393972             0.459674         0.385652              0.654799   \n",
       "4      0.590751             0.715137         0.555617              0.608359   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0         0.040813        0.118644             0.604136               0.311311  \n",
       "1         0.048793        0.271186             0.481536               0.217217  \n",
       "2         0.074848        0.161017             0.430576               0.279279  \n",
       "3         0.049216        0.093220             0.650665               0.080080  \n",
       "4         0.047168        0.144068             0.665436               0.086086  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"BankChurnersFNum.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "del df[\"Unnamed: 0\"]\n",
    "del df[\"CLIENTNUM\"]\n",
    "del df[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"]\n",
    "del df[\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\"]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Attrition_Flag\"], axis=1)\n",
    "Y = df[\"Attrition_Flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = np.array(X[0:int(0.80*len(X))])\\nY_train = np.array(Y[0:int(0.80*len(Y))])\\nX_test = np.array(X[int(0.80*len(X)):])\\nY_test = np.array(Y[int(0.80*len(Y)):])'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\"\"\"X_train = np.array(X[0:int(0.80*len(X))])\n",
    "Y_train = np.array(Y[0:int(0.80*len(Y))])\n",
    "X_test = np.array(X[int(0.80*len(X)):])\n",
    "Y_test = np.array(Y[int(0.80*len(Y)):])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression is 90.405904 percent accurate\n",
      "[[ 185  127]\n",
      " [  55 1530]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.59      0.67       312\n",
      "         1.0       0.92      0.97      0.94      1585\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.85      0.78      0.81      1897\n",
      "weighted avg       0.90      0.90      0.90      1897\n",
      "\n",
      "KNN is 89.615182 percent accurate\n",
      "[[ 155  157]\n",
      " [  40 1545]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.50      0.61       312\n",
      "         1.0       0.91      0.97      0.94      1585\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.85      0.74      0.78      1897\n",
      "weighted avg       0.89      0.90      0.89      1897\n",
      "\n",
      "Naive Bayes is 88.033737 percent accurate\n",
      "[[ 199  113]\n",
      " [ 114 1471]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.64      0.64       312\n",
      "         1.0       0.93      0.93      0.93      1585\n",
      "\n",
      "    accuracy                           0.88      1897\n",
      "   macro avg       0.78      0.78      0.78      1897\n",
      "weighted avg       0.88      0.88      0.88      1897\n",
      "\n",
      "Linear SVMs is 90.247760 percent accurate\n",
      "[[ 189  123]\n",
      " [  62 1523]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.61      0.67       312\n",
      "         1.0       0.93      0.96      0.94      1585\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.84      0.78      0.81      1897\n",
      "weighted avg       0.90      0.90      0.90      1897\n",
      "\n",
      "Non Linear SVMs is 92.514497 percent accurate\n",
      "[[ 208  104]\n",
      " [  38 1547]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.67      0.75       312\n",
      "         1.0       0.94      0.98      0.96      1585\n",
      "\n",
      "    accuracy                           0.93      1897\n",
      "   macro avg       0.89      0.82      0.85      1897\n",
      "weighted avg       0.92      0.93      0.92      1897\n",
      "\n",
      "Decision Trees is 94.254085 percent accurate\n",
      "[[ 259   53]\n",
      " [  56 1529]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.83      0.83       312\n",
      "         1.0       0.97      0.96      0.97      1585\n",
      "\n",
      "    accuracy                           0.94      1897\n",
      "   macro avg       0.89      0.90      0.90      1897\n",
      "weighted avg       0.94      0.94      0.94      1897\n",
      "\n",
      "Random Forests is 96.573537 percent accurate\n",
      "[[ 268   44]\n",
      " [  21 1564]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.86      0.89       312\n",
      "         1.0       0.97      0.99      0.98      1585\n",
      "\n",
      "    accuracy                           0.97      1897\n",
      "   macro avg       0.95      0.92      0.94      1897\n",
      "weighted avg       0.97      0.97      0.97      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "KNN = KNeighborsClassifier()\n",
    "NB = GaussianNB()\n",
    "LSVM = LinearSVC()\n",
    "NLSVM = SVC(kernel='rbf')\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "#\n",
    "LR_fit = LR.fit(X_train, Y_train)\n",
    "KNN_fit = KNN.fit(X_train, Y_train)\n",
    "NB_fit = NB.fit(X_train, Y_train)\n",
    "LSVM_fit = LSVM.fit(X_train, Y_train)\n",
    "NLSVM_fit = NLSVM.fit(X_train, Y_train)\n",
    "DT_fit = DT.fit(X_train, Y_train)\n",
    "RF_fit = RF.fit(X_train, Y_train)\n",
    "#\n",
    "LR_pred = LR_fit.predict(X_test)\n",
    "KNN_pred = KNN_fit.predict(X_test)\n",
    "NB_pred = NB_fit.predict(X_test)\n",
    "LSVM_pred = LSVM_fit.predict(X_test)\n",
    "NLSVM_pred = NLSVM_fit.predict(X_test)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "#\n",
    "print(\"Logistic Regression is %f percent accurate\" % (accuracy_score(LR_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, LR_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, LR_pred))\n",
    "#print ('Accuracy Score :',accuracy_score(Y_test, LR_pred))\n",
    "#\n",
    "print(\"KNN is %f percent accurate\" % (accuracy_score(KNN_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, KNN_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, KNN_pred))\n",
    "#\n",
    "print(\"Naive Bayes is %f percent accurate\" % (accuracy_score(NB_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, NB_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, NB_pred))\n",
    "#\n",
    "print(\"Linear SVMs is %f percent accurate\" % (accuracy_score(LSVM_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, LSVM_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, LSVM_pred))\n",
    "#\n",
    "print(\"Non Linear SVMs is %f percent accurate\" % (accuracy_score(NLSVM_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, NLSVM_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, NLSVM_pred))\n",
    "#\n",
    "print(\"Decision Trees is %f percent accurate\" % (accuracy_score(DT_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, DT_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, DT_pred))\n",
    "#\n",
    "print(\"Random Forests is %f percent accurate\" % (accuracy_score(RF_pred, Y_test)*100))\n",
    "print(confusion_matrix(Y_test, RF_pred))  \n",
    "print ('Report : ') \n",
    "print (classification_report(Y_test, RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests before tuning : 96.57353716394307 percent accurate\n",
      "Random Forests after tuning : 96.46810753821823 percent accurate\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "params = {'n_estimators': [*range(100, 1100, 100)], 'max_features': [*range(1, 20)]}\n",
    "\n",
    "rscv = RandomizedSearchCV(estimator=random_forest, param_distributions=params, random_state=0)\n",
    "rscv.fit(X_train, Y_train)\n",
    "values = rscv.best_params_\n",
    "random_forest_best = RandomForestClassifier(n_estimators = values['n_estimators'], max_features = values['max_features'])\n",
    "random_forest_best.fit(X_train, Y_train)\n",
    "Y_pred = random_forest_best.predict(X_test)\n",
    "print(\"Random Forests before tuning : {0} percent accurate\".format(accuracy_score(RF_pred, Y_test)*100))\n",
    "print(\"Random Forests after tuning : {0} percent accurate\".format(accuracy_score(Y_test, Y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[149  31]\n",
      " [ 14 860]]\n",
      "Accuracy Score : 0.9573055028462998\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.87       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.92      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[154  26]\n",
      " [ 12 862]]\n",
      "Accuracy Score : 0.9639468690702088\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.86      0.89       180\n",
      "         1.0       0.97      0.99      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.95      0.92      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[153  27]\n",
      " [ 14 860]]\n",
      "Accuracy Score : 0.961100569259962\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.92      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[151  29]\n",
      " [ 16 858]]\n",
      "Accuracy Score : 0.9573055028462998\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.84      0.87       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.91      0.92      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[155  25]\n",
      " [ 15 859]]\n",
      "Accuracy Score : 0.9620493358633776\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.89       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.92      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[150  30]\n",
      " [ 17 857]]\n",
      "Accuracy Score : 0.9554079696394687\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86       180\n",
      "         1.0       0.97      0.98      0.97       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.93      0.91      0.92      1054\n",
      "weighted avg       0.95      0.96      0.95      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[155  25]\n",
      " [ 15 859]]\n",
      "Accuracy Score : 0.9620493358633776\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.89       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.92      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[153  27]\n",
      " [ 16 858]]\n",
      "Accuracy Score : 0.959203036053131\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.92      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Confusion Matrix :\n",
      "[[154  26]\n",
      " [ 15 859]]\n",
      "Accuracy Score : 0.961100569259962\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88       180\n",
      "         1.0       0.97      0.98      0.98       874\n",
      "\n",
      "    accuracy                           0.96      1054\n",
      "   macro avg       0.94      0.92      0.93      1054\n",
      "weighted avg       0.96      0.96      0.96      1054\n",
      "\n",
      "Average K-Fold Score : 0.9599409656335653\n"
     ]
    }
   ],
   "source": [
    "#implement cross-validation\n",
    "kfold = KFold(9, shuffle=True, random_state=1)\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "scores = []\n",
    "\n",
    "for i in range(9):\n",
    "    result = next(kfold.split(df), None)\n",
    "    \n",
    "    X_train = df.iloc[result[0], 1:19]\n",
    "    X_test = df.iloc[result[1], 1:19]\n",
    "    \n",
    "    y_train = df.iloc[result[0], 0]\n",
    "    y_test = df.iloc[result[1], 0]\n",
    "    \n",
    "    classifier = classifier.fit(X_train,y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, predicted))\n",
    "    \n",
    "    print ('Confusion Matrix :') \n",
    "    print(confusion_matrix(y_test, predicted)) \n",
    "    print ('Accuracy Score :',accuracy_score(y_test, predicted)) \n",
    "    print ('Report : ') \n",
    "    print (classification_report(y_test, predicted)) \n",
    "    \n",
    "\n",
    "print('Average K-Fold Score :' , np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
